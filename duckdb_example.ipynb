{
 "cells": [
    {
        "attachments": {},
        "cell_type": "markdown",
        "metadata": {},
        "source": [
         "# Introduction to DuckDB and our Parquet files\n",
         "This notebook shows an example of how to:\n",
         "\n",
         "- Install the DuckDB Python packages\n",
         "- Import Parquet data from S3 by using the MayStreet Data library to retrieve a set of Parquet files based on table, feed, and date time\n",
         "- Import data from a local CSV into DuckDB.\n",
         "- Join the two datasets together in a SQL query.\n",
         "- Export data into CSV.\n"
        ]
       },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the DuckDB Python package via PIP\n",
    "\n",
    "! pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple file-backed database, sitting inside our /tmp folder.\n",
    "\n",
    "import duckdb\n",
    "\n",
    "con = duckdb.connect('/tmp/duckdb-cache-selectedcols.duckdb')\n",
    "\n",
    "con.execute('SET threads TO 4;')\n",
    "\n",
    "con.execute(\"INSTALL 'httpfs';\")\n",
    "con.execute(\"LOAD 'httpfs';\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all NBBO quotes for below table, feed, and date.\n",
    "\n",
    "import datetime\n",
    "import maystreet_data as md\n",
    "\n",
    "con.execute('DROP TABLE IF EXISTS all_a_trades;')\n",
    "\n",
    "\n",
    "# these may need to be changed if you do not have access to the feed and date below; use the Help --> View Data Feed Permissions command in this IDEA to see the date ranges and feeds\n",
    "# you're entitled to.\n",
    "\n",
    "source_table = \"mt_nbbo_quote\"\n",
    "source_feeds = [\"cqs_pillar\"]\n",
    "source_date = datetime.date(2022, 1, 3)\n",
    "\n",
    "files_list = md.parquet_query(source_table, source_feeds, source_date)\n",
    "s3_urls = map(lambda f: f\"'s3://{f}'\" if not f.startswith('https://') else f\"'{f}'\", files_list)\n",
    "\n",
    "\n",
    "# check that we actually have some data... if you don't, the import will fail.\n",
    "\n",
    "if len(list(s3_urls)) == 0:\n",
    "    raise BaseException('No files were provided for the above date range and feed; check you have permissions and modify the code if you do not.')\n",
    "\n",
    "\n",
    "# insert the data from our Parquet files.\n",
    "\n",
    "sql = f\"CREATE TABLE all_a_trades AS SELECT DISTINCT AskPrice, AskQuantity, BestAskParticipants, BidPrice, BidQuantity, BestBidParticipants, SequenceNumber FROM read_parquet([{', '.join(s3_urls)}]) WHERE Product = 'A' AND BestAskParticipants = 'DirectEdgeX';\"\n",
    "con.execute(sql)\n",
    "\n",
    "\n",
    "#  check to see how many rows we read in?\n",
    "\n",
    "number_entered = con.execute('SELECT COUNT(*) FROM all_a_trades;').fetchdf()\n",
    "number_entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a completely impractical and very slow way to retrieve the number of NBBO entries for cqs_pillar given the criteria below...\n",
    "\n",
    "import datetime\n",
    "import maystreet_data as md\n",
    "\n",
    "files_list = md.parquet_query(\"mt_nbbo_quote\", [\"cqs_pillar\"], datetime.date(2022, 1, 3))\n",
    "s3_urls = map(lambda f: f\"'s3://{f}'\" if not f.startswith('https://') else f\"'{f}'\", files_list)\n",
    "sql = f\"SELECT COUNT(*) FROM read_parquet([{', '.join(s3_urls)}]) WHERE Product = 'A' AND BestAskParticipants = 'DirectEdgeX';\"\n",
    "\n",
    "con.execute(sql).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert CSV data from our local directory into DuckDB.\n",
    "\n",
    "con = duckdb.connect('/tmp/duckdb-cache-selectedcols.duckdb')\n",
    "\n",
    "con.execute('DROP TABLE IF EXISTS example_csv;')\n",
    "\n",
    "sql = 'CREATE TABLE example_csv AS SELECT * FROM read_csv_auto(\"example_csv_file.csv\");'\n",
    "con.execute(sql)\n",
    "\n",
    "sql = 'SELECT * FROM example_csv;'\n",
    "data_frame = con.execute(sql).fetchdf()\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the NBBOs from LLG's data joined with the data we supplied.\n",
    "\n",
    "data_frame = con.execute('SELECT ex.*, at.* FROM example_csv ex LEFT JOIN all_a_trades at ON at.SequenceNumber = ex.SequenceID').fetchdf()\n",
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data into a file in the local directory\n",
    "\n",
    "con.execute(\"COPY all_a_trades TO '/home/workbench/all-a-trades-DirectEdgeX.csv' WITH (HEADER 1);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally close the connection\n",
    "\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
