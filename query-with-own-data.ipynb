{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combining your data and ours\n",
        "This notebook shows an example of how to:\n",
        "\n",
        "- Extract a technical indicator from our Data Lake into a Pandas dataframe\n",
        "- Import your own data in a queryable format\n",
        "- Join the two datasets together in a SQL query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# You must choose a particular feed and date to use for the queries in this notebook. \n",
        "# If you need a list of feeds, go to Help Menu -> \"View Feed Data Permissions\"\n",
        "\n",
        "dt = '2025-02-05'\n",
        "product = 'AAPL'\n",
        "feed = 'xdp_nyse_integrated'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install duckdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import duckdb\n",
        "import maystreet_data as md\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we run an SQL query against the Data Lake to extract TWAP for crude oil futures by minute, and then store the result inside a Pandas dataframe.\n",
        "\n",
        "You can also create an S3 bucket resource from the launcher, and store files there. Buckets can be shared between users, allowing to share datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = f\"\"\"\n",
        "-- TWAP\n",
        "\n",
        "-- NOTE: \"period_start\" field is in UTC and period is currently 1 minute\n",
        "WITH\n",
        "    product_trades AS (\n",
        "        SELECT\n",
        "            price,\n",
        "            exchangetimestamp,\n",
        "            DATE_TRUNC(\n",
        "                'minute',\n",
        "                FROM_UNIXTIME(exchangetimestamp / 1e9)\n",
        "            ) AS period_start\n",
        "        FROM\n",
        "            mt_trade\n",
        "        WHERE\n",
        "            f = '{feed}'\n",
        "            AND dt = '{dt}'\n",
        "            AND product = '{product}'\n",
        "            -- if we wanted to filter by time of day\n",
        "            -- AND FROM_UNIXTIME(exchangetimestamp / 1e9) BETWEEN TIMESTAMP '2022-09-18 14:30:00' AND TIMESTAMP '2022-09-18 21:00:00'\n",
        "    ),\n",
        "    period_twap_prep AS (\n",
        "        SELECT\n",
        "            exchangetimestamp,\n",
        "            period_start,\n",
        "            RANK() OVER (\n",
        "                PARTITION BY period_start\n",
        "                ORDER BY \n",
        "                    exchangetimestamp ASC\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            ) AS rnk,\n",
        "            FIRST_VALUE(price) OVER (\n",
        "                PARTITION BY period_start\n",
        "                ORDER BY\n",
        "                    exchangetimestamp ASC\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            ) AS first_price,\n",
        "            LAST_VALUE(price) OVER (\n",
        "                PARTITION BY period_start\n",
        "                ORDER BY\n",
        "                    exchangetimestamp ASC\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            ) AS last_price,\n",
        "            MIN(price) OVER (\n",
        "                PARTITION BY period_start\n",
        "                ORDER BY exchangetimestamp ASC\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            ) AS min_price,\n",
        "            MAX(price) OVER (\n",
        "                PARTITION BY period_start\n",
        "                ORDER BY exchangetimestamp ASC\n",
        "                ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n",
        "            ) AS max_price\n",
        "        FROM\n",
        "            product_trades\n",
        "    ),\n",
        "    max_ranks AS (\n",
        "        SELECT\n",
        "            period_start,\n",
        "            MAX(rnk) AS max_rank\n",
        "        FROM\n",
        "            period_twap_prep\n",
        "        GROUP BY\n",
        "            period_start\n",
        "    ),\n",
        "    each_period as (\n",
        "        SELECT\n",
        "            prep.period_start,\n",
        "            prep.first_price,\n",
        "            prep.last_price,\n",
        "            prep.min_price,\n",
        "            prep.max_price\n",
        "        FROM\n",
        "            period_twap_prep prep\n",
        "                JOIN\n",
        "            max_ranks ranks ON prep.period_start = ranks.period_start AND prep.rnk = ranks.max_rank\n",
        "    ),\n",
        "    twap_components AS (\n",
        "        SELECT\n",
        "            period_start,\n",
        "            (min_price + max_price + first_price + last_price) / 4 AS period_typical_price\n",
        "        FROM\n",
        "            each_period\n",
        "    )\n",
        "SELECT\n",
        "    *,\n",
        "    AVG(period_typical_price) OVER (ORDER BY period_start) AS twap\n",
        "FROM\n",
        "    twap_components\n",
        "ORDER BY\n",
        "    period_start\n",
        "\"\"\"\n",
        "\n",
        "twap_extract = pd.DataFrame(md.query(md.DataSource.DATA_LAKE, query))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import our data. In this case, we're randomly generating 100 bids and storing them inside a Pandas dataframe.\n",
        "\n",
        "In practice, you'll want to use one of the following options to import real data:\n",
        "\n",
        "- Store your data in your own S3 bucket, and allow the Workbench AWS role read access to it.\n",
        "- Connect to your own storage from the workbench.\n",
        "- If it's a small file, directly upload it by dragging the file into the Explorer in the Workbench interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "start = 1663538400000000000\n",
        "end = start + 60 * 60 * 1000000000\n",
        "timestamps = np.random.randint(start, end, 100)\n",
        "bid = np.random.randint(8480, 8520, 100)\n",
        "random_orders = pd.DataFrame(dict(timestamp=timestamps, bid=bid))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use [DuckDB](https://duckdb.org/) to query the data together; note that DuckDB natively understands how to query data stored in a Pandas\n",
        "dataframe in the same context without any additional configuration.\n",
        "\n",
        "In this query, we're putting our bids together with the TWAP metrics in a single list, orderered by timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "    random_orders.timestamp,\n",
        "    random_orders.bid AS price,\n",
        "    'bid' AS type\n",
        "FROM\n",
        "    random_orders\n",
        "UNION ALL\n",
        "SELECT\n",
        "    twap_extract.period_start * 1000000 AS timestamp,\n",
        "    twap_extract.twap AS price,\n",
        "    'twap' AS type\n",
        "FROM\n",
        "    twap_extract\n",
        "ORDER BY\n",
        "    timestamp\n",
        "LIMIT 100 -- only show the first 100 for this example\n",
        "\"\"\"\n",
        "\n",
        "with pd.option_context('display.max_rows', None):\n",
        "    display(duckdb.query(query).df())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".virtualenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
